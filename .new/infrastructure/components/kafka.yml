# ============================================================================
# Apache Kafka - Enterprise Event Streaming Platform
# ============================================================================
#
# PURPOSE:
#   Production-grade message broker enabling event-driven architecture for
#   Video RAG system. Provides fault-tolerant, scalable message streaming
#   with enterprise security, monitoring, and performance optimizations.
#
# ENTERPRISE FEATURES:
#   - Resource limits and reservations for predictable performance
#   - Security hardening with privilege restrictions and network isolation
#   - Production-tuned JVM settings for high-throughput messaging
#   - Comprehensive logging with structured format and rotation
#   - Optimized health monitoring with reduced check intervals
#
# PRODUCTION CHARACTERISTICS:
#   - Memory: 2GB reserved, 4GB limit (optimized for message buffering)
#   - CPU: 1.0 cores reserved, 2.0 cores limit (handles concurrent consumers)
#   - Security: Non-privileged execution with no privilege escalation
#   - Logging: JSON structured logs with 10MB rotation
#   - Monitoring: Broker API health checks every 15 seconds
#
# ROLE IN VIDEO RAG PIPELINE:
#   1. Receives video frames from Frame Producer (raw-frames topic)
#   2. Distributes frames to parallel Vision Services (OCR, Detection, etc.)
#   3. Collects vision results for Frame Aggregator
#   4. Streams aggregated data through Summarizer → Segmenter → RAG Storage
#
# KAFKA TOPICS ARCHITECTURE:
#   - raw-frames              → Input frames from video sources
#   - ocr-results            → Text extraction results
#   - detection-results      → Object detection results
#   - caption-results        → Image captioning results
#   - embedding-results      → Visual embeddings
#   - scene-graph-results    → Spatial relationships
#   - aggregated-frame-metadata → Combined vision results
#   - frame-summaries        → LLM-generated summaries
#   - video-segments         → Final segmented content
#
# PERFORMANCE TUNING:
#   - Message retention: 1 hour (configurable for production needs)
#   - Max message size: 10MB (accommodates base64 encoded video frames)
#   - Batch processing: Optimized for high-throughput video processing
#   - Compression: LZ4 compression for network efficiency
#   - Replication: Single broker (scale to 3+ brokers for production HA)
#
# SECURITY & COMPLIANCE:
#   - Network isolation via dedicated bridge network
#   - No privilege escalation allowed during runtime
#   - Data encryption at rest via volume encryption (external)
#   - Access control via network policies and firewall rules
#
# MONITORING & OBSERVABILITY:
#   - Health endpoint: Broker API availability checks
#   - Metrics: JMX metrics for throughput, latency, and consumer lag
#   - Log aggregation: Structured JSON logs for centralized monitoring
#   - Alerting: Health check failures trigger automatic restart
#
# ============================================================================

services:
  kafka:
    # Official Confluent Kafka image with enterprise features
    image: ${KAFKA_IMAGE}
    container_name: ${KAFKA_CONTAINER_NAME}
    hostname: kafka # Fixed hostname for consistent service discovery

    # OrbStack will automatically create: kafka.video-rag.orb.local

    # Dependency management - wait for Zookeeper to be healthy
    depends_on:
      zookeeper:
        condition: service_healthy # Ensures Zookeeper is ready before Kafka starts

    # Port mapping for dual listener configuration
    ports:
      # Internal communication port (container-to-container)
      - "${KAFKA_HOST_PORT_INTERNAL}:${KAFKA_LISTENER_PORT_INTERNAL}" # 9092:9092

      # External communication port (host-to-container)
      - "${KAFKA_HOST_PORT_EXTERNAL}:${KAFKA_LISTENER_PORT_EXTERNAL}" # 9093:9093

    # Production Kafka broker configuration with validation
    environment:
      # Required: Unique broker identifier in cluster
      KAFKA_BROKER_ID: ${KAFKA_BROKER_ID:?Kafka broker ID required}

      # Required: Zookeeper connection string for cluster coordination
      KAFKA_ZOOKEEPER_CONNECT: ${KAFKA_ZOOKEEPER_CONNECT:?Zookeeper connection required}

      # Advertised listeners - how clients discover and connect to broker
      # PLAINTEXT: Internal Docker network communication
      # PLAINTEXT_HOST: External host access via OrbStack automatic domain
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:${KAFKA_LISTENER_PORT_INTERNAL},PLAINTEXT_HOST://kafka.video-rag.orb.local:${KAFKA_LISTENER_PORT_EXTERNAL}

      # Security protocol mapping for each listener
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT

      # Inter-broker communication protocol
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT

      # Replication settings for internal topics (production: increase to 3)
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: ${KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR:?Replication factor required}
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1

      # Topic management (disable auto-creation in production)
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: ${KAFKA_AUTO_CREATE_TOPICS_ENABLE:?Auto create topics setting required}
      KAFKA_DELETE_TOPIC_ENABLE: true

      # Message retention and performance tuning
      KAFKA_LOG_RETENTION_HOURS: ${KAFKA_LOG_RETENTION_HOURS:?Log retention hours required}
      KAFKA_LOG_SEGMENT_BYTES: ${KAFKA_LOG_SEGMENT_BYTES:?Log segment bytes required}
      KAFKA_MESSAGE_MAX_BYTES: ${KAFKA_MESSAGE_MAX_BYTES:?Message max bytes required}
      KAFKA_REPLICA_FETCH_MAX_BYTES: ${KAFKA_REPLICA_FETCH_MAX_BYTES:?Replica fetch max bytes required}

      # Production performance optimizations
      KAFKA_COMPRESSION_TYPE: lz4 # Efficient compression for video data
      KAFKA_BATCH_SIZE: 65536 # Larger batches for better throughput
      KAFKA_LINGER_MS: 10 # Small delay for batching efficiency
      KAFKA_BUFFER_MEMORY: 134217728 # 128MB buffer for high throughput

      # JVM heap optimization for message broker workload
      KAFKA_HEAP_OPTS: "-Xmx2g -Xms1g"

      # JVM GC tuning for high-throughput messaging
      KAFKA_JVM_PERFORMANCE_OPTS: "-XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35"

      # Production logging configuration
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"

    # Persistent storage for Kafka logs and state
    volumes:
      # Kafka data directory - contains topic partitions and logs
      - ${KAFKA_VOLUME_DATA}:/var/lib/kafka/data

    # Production resource management
    deploy:
      resources:
        # Resource limits to prevent system overload
        limits:
          memory: 4G # Maximum memory allocation for message buffering
          cpus: '2.0' # Maximum CPU cores for concurrent processing
        # Resource reservations for guaranteed performance
        reservations:
          memory: 2G # Guaranteed memory for message broker operations
          cpus: '1.0' # Guaranteed CPU for consistent throughput

    # Enterprise security configuration
    security_opt:
      # Prevent privilege escalation attacks
      - no-new-privileges:true
    
    # Production logging configuration
    logging:
      driver: "json-file"
      options:
        # Log rotation to prevent disk space issues
        max-size: "10m" # Maximum log file size
        max-file: "3" # Number of rotated log files to keep
        # Structured logging for centralized log aggregation
        labels: "service=kafka,environment=production,component=message-broker"

    # Network configuration
    networks:
      - ${NETWORK_NAME} # video-rag-network bridge

    # Production restart policy
    restart: unless-stopped

    # Optimized health check configuration
    healthcheck:
      # Test broker API availability using Kafka tools
      test:
        [
          "CMD",
          "kafka-broker-api-versions",
          "--bootstrap-server",
          "localhost:${KAFKA_LISTENER_PORT_INTERNAL}",
        ]

      # Production-tuned check intervals
      interval: 15s # More frequent checks for critical message broker
      timeout: 5s # Reasonable timeout for API response
      retries: 3 # Quick failover for message broker
      start_period: 45s # Allow time for broker initialization

# Named volume for Kafka data persistence
volumes:
  video-rag-kafka-data:
    name: ${KAFKA_VOLUME_DATA}
    external: true


# Network configuration
networks:
  video-rag-network:
    driver: bridge
    name: video-rag-network
    external: true
