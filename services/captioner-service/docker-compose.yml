# ============================================================================
# Image Captioning Service - Natural Language Description Generator
# ============================================================================
#
# PURPOSE:
#   Generates natural language descriptions of video frame content using
#   transformer-based vision-language models (BLIP/BLIP-2). Provides semantic
#   understanding of visual scenes for enhanced video comprehension.
#
# ROLE IN VIDEO RAG PIPELINE:
#   Input:  raw-frames topic (base64 encoded video frames)
#   Process: Image-to-text generation using BLIP models
#   Output: caption-results topic (natural language descriptions)
#
# PROCESSING WORKFLOW:
#   1. Consume frame messages from Kafka 'raw-frames' topic
#   2. Decode base64 image data to PIL/tensor format
#   3. Run BLIP inference for image captioning
#   4. Generate natural language descriptions
#   5. Publish structured captions to 'caption-results' topic
#
# CAPTIONING CAPABILITIES:
#   - Scene description and object relationships
#   - Action and activity recognition
#   - Spatial and temporal context understanding
#   - Multi-object scene interpretation
#   - Contextual narrative generation
#
# MODEL SUPPORT:
#   - BLIP (Bootstrapped Language-Image Pre-training)
#   - BLIP-2 with improved efficiency
#   - Custom fine-tuned models
#   - Configurable generation parameters
#
# PERFORMANCE CHARACTERISTICS:
#   - GPU acceleration via NVIDIA CUDA
#   - ~100-150ms inference time per frame
#   - Memory usage: ~3-5GB GPU RAM (model dependent)
#   - Batch processing for efficiency
#   - Transformer attention mechanisms
#
# OUTPUT FORMAT:
#   {
#     "frame_id": "uuid",
#     "service": "captioner-service",
#     "timestamp": 1234567890.456,
#     "results": {
#       "caption": "a person walking with a dog in a park",
#       "confidence": 0.92,
#       "word_count": 9,
#       "generation_params": {...}
#     },
#     "processing_time_ms": 125.7
#   }
#
# DEPENDENCIES:
#   - Kafka cluster (healthy)
#   - NVIDIA GPU with CUDA support
#   - Transformers library with BLIP models
#   - PyTorch with vision transformers
#
# MONITORING:
#   - Health endpoint: http://localhost:8003/health
#   - Caption quality and generation metrics
#   - Model loading status and GPU utilization
#
# ============================================================================

services:
  captioner-service:
    # Build from local Dockerfile with transformer dependencies
    build:
      context: . # Current service directory
      dockerfile: Dockerfile

    container_name: ${CAPTIONER_SERVICE_CONTAINER_NAME}
    hostname: captioner-service # Fixed hostname for service discovery
    
    # OrbStack will automatically create: captioner-service.video-rag.orb.local

    # Port mapping for health checks and debugging
    ports:
      # HTTP API for health checks and optional direct captioning
      - "${CAPTIONER_SERVICE_HOST_PORT}:${CAPTIONER_SERVICE_INTERNAL_PORT}" # 8003:8000

    # Service configuration via environment variables
    environment:
      # Kafka connection configuration
      - KAFKA_BOOTSTRAP_SERVERS=${KAFKA_BOOTSTRAP_SERVERS} # kafka:9092

      # Topic configuration for message flow
      - KAFKA_INPUT_TOPIC=${KAFKA_TOPIC_RAW_FRAMES} # raw-frames
      - KAFKA_OUTPUT_TOPIC=${KAFKA_TOPIC_CAPTION_RESULTS} # caption-results

      # Consumer group for load balancing
      - KAFKA_CONSUMER_GROUP=${CAPTIONER_SERVICE_CONSUMER_GROUP} # captioner-service-group

      # Service identification
      - SERVICE_NAME=${CAPTIONER_SERVICE_NAME} # captioner-service

      # Logging configuration
      - LOG_LEVEL=${LOG_LEVEL} # INFO/DEBUG

    # Note: Kafka dependency managed by infrastructure startup order

    # Network configuration
    networks:
      - ${NETWORK_NAME} # video-rag-network bridge

    # Restart policy
    restart: unless-stopped

    # Production resource management (CPU-only mode)
    deploy:
      resources:
        limits:
          memory: 6G # Maximum memory for captioning processing
          cpus: '2.0' # Maximum CPU cores for captioning
        reservations:
          memory: 3G # Guaranteed memory for processing
          cpus: '1.0' # Guaranteed CPU for consistent processing

    # Enterprise security configuration
    security_opt:
      - no-new-privileges:true
    
    # Production logging configuration
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service=captioner-service,environment=production,component=vision-processing"

# Network reference - managed by infrastructure
networks:
  video-rag-network:
    name: ${NETWORK_NAME}
    external: true # Network created by infrastructure services
